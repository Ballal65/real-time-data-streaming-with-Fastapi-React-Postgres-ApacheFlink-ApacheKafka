services:       
#Airflow init
  airflow-init:
    build:
      context: .
      dockerfile: dockerfile.airflow
    container_name: airflow-init
    image: airflow-init
    env_file:
      .env
    entrypoint: ["airflow", "db", "init"]
    depends_on:
      - postgres
    networks:
      - custom_network
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"

# Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: dockerfile.airflow
    container_name: airflow-webserver
    image: airflow-webserver
    env_file:
      - .env
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /home/ompathare/extracted_data:/opt/airflow/extracted_data:z
      - /home/ompathare/transformed_data:/opt/airflow/transformed_data:z
    ports:
      - "8080:8080"
    depends_on:
      - airflow-scheduler
      - postgres
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - custom_network
    command: >
      bash -c "
      sleep 20 &&
      airflow webserver"

# Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: dockerfile.airflow
    container_name: airflow-scheduler
    image: airflow-scheduler
    env_file:
      - .env
    user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /home/ompathare/extracted_data:/opt/airflow/extracted_data:z
      - /home/ompathare/transformed_data:/opt/airflow/transformed_data:z
    depends_on:
      - postgres
    networks:
      - custom_network

    command: >
      bash -c "
      airflow db init &&
      airflow users create --username airflow --firstname Ballal --lastname Pathare --role Admin --email ballalpathare65@gmail.com --password airflow || true &&
      airflow scheduler"

# Flink JobManager
  jobmanager:
    build:
      context: .
      dockerfile: dockerfile.flink
    container_name: jobmanager
    image: jobmanager
    hostname: jobmanager
    env_file:
      - .env
    expose:
      - "6123"
    ports:
      - "8081:8081" # Flink Web UI
      - "6123:6123"  # RPC port for JobManager communication
    volumes:
      - ./flink/jobs:/flink/jobs
    command: jobmanager
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - kafka
      - postgres
    networks:
      - custom_network

# Flink TaskManager
  taskmanager:
    image: flink:1.16.0
    container_name: taskmanager
    env_file:
      - .env
    expose:
      - "6121"
      - "6122"
    depends_on:
      - jobmanager
      - postgres
    volumes:
      - ./flink/jobs:/flink/jobs
    command: taskmanager
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - custom_network

#Zoopkeeper for Kafka
  zookeeper:
    container_name: zookeeper
    image: confluentinc/cp-zookeeper:latest
    restart: on-failure
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"
    networks:
      - custom_network

#Kafka broker
  kafka:
    container_name: kafka
    image: confluentinc/cp-kafka:latest
    restart: on-failure
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    networks:
      - custom_network

#Kafka UI
  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop
    restart: on-failure
    depends_on:
      - kafka
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
    ports:
      - "9000:9000"
    networks:
      - custom_network

#Postgres Database     
  postgres:
    image: postgres:14
    restart: on-failure
    container_name: postgres
    env_file:
      - .env
    environment:
      - POSTGRES_DB=${POSTGRES_SCHEMA}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - custom_network

#pgAdmin UI for Postgres Database
  pgadmin:
    container_name: pgadmin
    image: dpage/pgadmin4
    restart: on-failure
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_PASSWORD}
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    networks:
      - custom_network

#FastAPI Backend
  backend:
    build: 
      context: .
      dockerfile: dockerfile.backend
    image: backend
    restart: on-failure
    container_name: backend
    command: ["python", "-m", "app.main", "true"]
    volumes:
      - ./backend:/code
    ports:
      - "8000:8000"
    depends_on:
      - postgres
      - kafka
    env_file:
      - .env
    networks:
      - custom_network

#React frontend
  frontend:
    build: 
      context: .
      dockerfile: dockerfile.frontend
    image: frontend
    restart: on-failure
    container_name: frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    env_file:
      - .env
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    environment:
      - CHOKIDAR_USEPOLLING=true
    command: ["npm", "start"]
    networks:
      - custom_network

volumes:
  postgres-data:
  pgadmin-data:
  airflow-logs:
  airflow-dags:
  airflow-plugins:

networks:
  custom_network:
    driver: bridge
